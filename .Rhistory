# English
en <- read_xlsx("ENCOW_x_is_the_new_y_without_false_hits.xlsx")
# load packages
library(readxl)
library(tidyverse)
library(patchwork)
# English
en <- read_xlsx("ENCOW_x_is_the_new_y_without_false_hits.xlsx")
# Spanish
es <- read_xlsx("ESCOW_x_nuev_y_without_false_hits.xlsx")
en$keep
filter(en, keep=="y")
en <- filter(en, keep=="y")
es <- filter(es, keep=="y")
es
library(vroom)
decow <- vroom("/Users/stefanhartmann/Downloads/decow16bx.lp.tsv.gz")
escow <- vroom("/Users/stefanhartmann/sciebo/Projekte/snowclones/ESCOW frequency lists/escow14ax.freq0.l.zip")
escow
encow <- vroom("/Users/stefanhartmann/sciebo/Tutorials/collostructions_tutorial/data/encow16ax.lp.tsv.gz")
decow
decow <- vroom("/Users/stefanhartmann/Downloads/decow16bx.lp.tsv.gz", col_names = c("Lemma", "POS", "Freq"))
escow <- vroom("/Users/stefanhartmann/sciebo/Projekte/snowclones/ESCOW frequency lists/escow14ax.freq0.l.zip", col_names = c("Lemma", "Freq"))
encow <- vroom("/Users/stefanhartmann/sciebo/Tutorials/collostructions_tutorial/data/encow16ax.lp.tsv.gz", col_names = c("Lemma", "POS", "Freq"))
View(es)
es_lemmas <- unique(c(es$Lemma_x, es$Lemma_y))
# which ESCOW lemmas in es_lemmas?
find_lemmas <- which(escow$Lemma %in% es_lemmas)
escow[find_lemmas,]
head(escow, 10) %>% View()
escow <- vroom("/Users/stefanhartmann/sciebo/Projekte/snowclones/ESCOW frequency lists/escow14ax.freq0.l.zip")
colnames(escow)
# which ESCOW lemmas in es_lemmas?
find_lemmas <- which(escow$token... %in% es_lemmas)
escow <- escow[find_lemmas,]
write_csv(escow, "es_cow_lemmas.csv")
escow <- read_csv("es_cow_lemmas.csv")
# ESCOW pos frequencies
es_pos <- read_csv("frequency_lists/ESCOW_pos_frequencies.csv")
View(es_pos)
?filter
head(es_pos)
unique(es_pos$pos)
# get total number of nouns and adjectives
filter(es_pos, pos %in% c("NOUN", "ADP", "PROPN", "ADJ"))
# get total number of nouns and adjectives
filter(es_pos, pos %in% c("NOUN", "ADP", "PROPN", "ADJ")) %>% select(frequency)
# get total number of nouns and adjectives
filter(es_pos, pos %in% c("NOUN", "ADP", "PROPN", "ADJ")) %>% select(frequency) %>% sum
# get total number of nouns and adjectives
n_a_freq <- filter(es_pos, pos %in% c("NOUN", "ADP", "PROPN", "ADJ")) %>% select(frequency) %>% sum
library(collostructions)
# collostructional analysis
es_lemmas
# collostructional analysis
escow$token...
# collostructional analysis
escow$Lemma <- tolower(escow$token...)
# lowercase lemmas
es$lemma_x <- tolower(es$Lemma_x)
es$lemma_y <- tolower(es$Lemma_y)
# create input for coll. anal. for
# x slot
table(es$lemma_x)
# create input for coll. anal. for
# x slot
table(es$lemma_x) %>% as_tibble()
?as_tibble
# create input for coll. anal. for
# x slot
table(es$lemma_x) %>% as_tibble(.name_repair="unique")
# create input for coll. anal. for
# x slot
table(es$lemma_x) %>% as_tibble(.name_repair="unique") %>% setNames(c("Lemma", "Freq_in_cxn"))
# create input for coll. anal. for
# x slot
input_x <- table(es$lemma_x) %>% as_tibble(.name_repair="unique") %>% setNames(c("Lemma", "Freq_in_cxn"))
# lowercase lemma in
escow$Ã¶emma <- tolower(escow$token...)
# lowercase lemma in escow
escow$lemma <- tolower(escow$token...)
select(escow, lemma, f_raw)
left_join(input_x, select(escow, lemma, f_raw),
by = c("Lemma" = "lemma"))
left_join(input_x, select(escow, lemma, f_raw),
by = c("Lemma" = "lemma")) %>% na.omit
left_join(input_x, select(escow, lemma, f_raw),
by = c("Lemma" = "lemma"))
input_x <- left_join(input_x, select(escow, lemma, f_raw),
by = c("Lemma" = "lemma"))
input_x %>% replace_na(list(Freq_in_cxn = 0, f_raw = 0))
# replace NA by 0
input_x <- input_x %>% replace_na(list(Freq_in_cxn = 0, f_raw = 0))
# omit all with f_raw < Freq_in_cxn
which(input_x$f_raw<input_x$Freq_in_cxn)
# omit all with f_raw < Freq_in_cxn
input_x[!which(input_x$f_raw<input_x$Freq_in_cxn),]
# omit all with f_raw < Freq_in_cxn
input_x[which(input_x$f_raw>=input_x$Freq_in_cxn),]
# omit all with f_raw < Freq_in_cxn
input_x <- input_x[which(input_x$f_raw>=input_x$Freq_in_cxn),]
# coll. anal.
collex(input_x, corpsize = n_a_freq)
?collex
input_x
# coll. anal.
collex(as.data.frame(input_x), corpsize = n_a_freq)
# coll. anal.
collex_x <- collex(as.data.frame(input_x), corpsize = n_a_freq)
# create input for coll. anal. for
# x slot
input_y <- table(es$lemma_y) %>% as_tibble(.name_repair="unique") %>% setNames(c("Lemma", "Freq_in_cxn"))
input_y <- left_join(input_y, select(escow, lemma, f_raw),
by = c("Lemma" = "lemma"))
# replace NA by 0
input_y <- input_y %>% replace_na(list(Freq_in_cxn = 0, f_raw = 0))
# omit all with f_raw < Freq_in_cxn
input_y <- input_y[which(input_y$f_raw>=input_y$Freq_in_cxn),]
# coll. anal.
collex_y <- collex(as.data.frame(input_y), corpsize = n_a_freq)
# load packages
library(readxl)
library(tidyverse)
library(patchwork)
library(vroom)
library(collostructions)
# English
en <- read_xlsx("ENCOW_x_is_the_new_y_without_false_hits.xlsx")
# Spanish
es <- read_xlsx("ESCOW_x_nuev_y_without_false_hits.xlsx")
en <- filter(en, keep=="y")
es <- filter(es, keep=="y")
# lemma list ES
es_lemmas <- unique(c(es$Lemma_x, es$Lemma_y))
# which ESCOW lemmas in es_lemmas?
find_lemmas <- which(escow$token... %in% es_lemmas)
escow <- escow[find_lemmas,]
# ESCOW lemma frequencies
escow <- read_csv("es_cow_lemmas.csv")
# ESCOW pos frequencies
es_pos <- read_csv("frequency_lists/ESCOW_pos_frequencies.csv")
# get total number of nouns and adjectives
n_a_freq <- filter(es_pos, pos %in% c("NOUN", "ADP", "PROPN", "ADJ")) %>% select(frequency) %>% sum
# lowercase lemmas
es$lemma_x <- tolower(es$Lemma_x)
es$lemma_y <- tolower(es$Lemma_y)
# create input for coll. anal. for
# x slot
input_x <- table(es$lemma_x) %>% as_tibble(.name_repair="unique") %>% setNames(c("Lemma", "Freq_in_cxn"))
# lowercase lemma in escow
escow$lemma <- tolower(escow$token...)
input_x <- left_join(input_x, select(escow, lemma, f_raw),
by = c("Lemma" = "lemma"))
# replace NA by 0
input_x <- input_x %>% replace_na(list(Freq_in_cxn = 0, f_raw = 0))
# omit all with f_raw < Freq_in_cxn
input_x <- input_x[which(input_x$f_raw>=input_x$Freq_in_cxn),]
# coll. anal.
collex_x <- collex(as.data.frame(input_x), corpsize = n_a_freq)
# create input for coll. anal. for
# x slot
input_y <- table(es$lemma_y) %>% as_tibble(.name_repair="unique") %>% setNames(c("Lemma", "Freq_in_cxn"))
input_y <- left_join(input_y, select(escow, lemma, f_raw),
by = c("Lemma" = "lemma"))
# replace NA by 0
input_y <- input_y %>% replace_na(list(Freq_in_cxn = 0, f_raw = 0))
# omit all with f_raw < Freq_in_cxn
input_y <- input_y[which(input_y$f_raw>=input_y$Freq_in_cxn),]
library(DT)
es %>% select(lemma_x, lemma_y) %>% as.data.frame() %>% collex.covar()
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2: sessionInfo
sessionInfo()
# Chunk 3: pkg
# install CRAN packages (if not yet installed)
sapply(c("readxl", "tidyverse", "patchwork", "devtools", "vroom", "DT"), function(x) if(!is.element(x, installed.packages())) install.packages(x, dependencies = T))
# install non-CRAN packages (if not yet installed)
if(!is.element("concordances", installed.packages())) {
devtools::install_github("hartmast/concordances")
}
# if this doesn't work, check sfla.ch for the package
if(!is.element("collostructions", installed.packages())) {
install.packages("https://sfla.ch/wp-content/uploads/2021/02/collostructions_0.2.0.tar.gz", repos = NULL)
}
# load packages
library(readxl)
library(tidyverse)
library(patchwork)
library(vroom)
library(collostructions)
library(DT)
# Chunk 4
# English
en <- read_xlsx("ENCOW_x_is_the_new_y_without_false_hits.xlsx")
# Spanish
es <- read_xlsx("ESCOW_x_nuev_y_without_false_hits.xlsx")
en <- filter(en, keep=="y")
es <- filter(es, keep=="y")
decow <- vroom("/Users/stefanhartmann/Downloads/decow16bx.lp.tsv.gz", col_names = c("Lemma", "POS", "Freq"))
# German
de <- read_xlsx("DECOW_x_ist_das_neue_y_without_false_hits.xlsx")
de <- filter(de, keep=="y")
# lemma list DE
de_lemmas <- unique(c(de$Lemma_x, de$Lemma_y))
# which DECOW lemmas in de_lemmas?
find_lemmas_de <- which(decow$Lemma %in% de_lemmas)
decow <- decow[find_lemmas_de,]
write_csv(decow, "de_cow_lemmas.csv")
