wwwusage <- tibble(time = 1:100, WWWusage = WWWusage)
wwwusage
wwwusage %>% ggplot(aes(x = time, y = WWWusage)) + geom_point()
wwwusage %>% ggplot(aes(x = time, y = WWWusage)) + geom_point() + geom_line()
wwwusage %>% ggplot(aes(x = time, y = WWWusage)) +
geom_point() + geom_line(lwd = 1.5)
wwwusage %>% ggplot(aes(x = time, y = WWWusage)) +
geom_point() + geom_line(lwd = 1.5) + xlab("Time")
wwwusage %>% ggplot(aes(x = time, y = WWWusage)) +
geom_point() + geom_line(lwd = 1.5) + xlab("Time") + ylab("www usage")
wwwusage %>% ggplot(aes(x = time, y = WWWusage)) +
geom_point() + geom_line(lwd = 1.5) + xlab("Time") + ylab("www usage") +
theme(axis.text = element_text(size = 18))
wwwusage %>% ggplot(aes(x = time, y = WWWusage)) +
geom_point() + geom_line(lwd = 1.5) + xlab("Time") + ylab("www usage") +
theme(axis.text = element_text(size = 18),
axis.title = element_text(size = 18))
spl
tibble(x = spl)
tibble(x = spl) %>% ggplot(aes(x = x)) + geom_bar()
?geom_col()
tbl
tbl %>% as_tibble()
tbl %>% as_tibble() %>% ggplot(aes(x = spl, y = n)) + geom_col()
tibble(x = spl) %>% ggplot(aes(x = x)) + geom_bar()
tbl %>% as_tibble() %>% ggplot(aes(x = spl, y = n)) + geom_col()
tbl %>% as_tibble() %>% ggplot(aes(x = spl, y = n)) + geom_col() +
xlab("Letter")
tbl %>% as_tibble() %>% ggplot(aes(x = spl, y = n)) + geom_col() +
xlab("Letter") + ylab("Frequency")
spl
spl01 <- tibble(letters = spl)
spl01
ifelse(spl01$letters %in% LETTERS[1:5], "A-E", "F-K"  )
spl01$group <- ifelse(spl01$letters %in% LETTERS[1:5], "A-E", "F-K")
spl01
spl01 %>%
ggplot(aes(x = group, fill = letters))
spl01 %>%
ggplot(aes(x = group, fill = letters)) +
geom_bar()
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar()
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_manual(values = c("blue", "green"))
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_manual(values = c("blue", "darkgreen"))
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_viridis_d()
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = .8)
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = ..1)
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = .1)
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = .2)
spl01 %>%
ggplot(aes(x = letters, fill = group, col = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = .2)
spl01 %>%
ggplot(aes(x = letters, fill = group, col = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = .2) +
scale_color_manual(values = c("yellow", "orange"))
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = .2)
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = .2) +
geom_text()
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = .2) +
geom_text(stat = "count", aes(label = letters))
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = .2) +
geom_text(stat = "count", aes(label = letters),
position = position_stack(vjust = .5))
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = .2) +
geom_text(stat = "count", aes(label = letters),
position = position_stack(vjust = .5), col = "white")
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = 1) +
geom_text(stat = "count", aes(label = letters),
position = position_stack(vjust = .5), col = "white")
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = 1) +
geom_text(stat = "count", aes(label = letters),
position = position_stack(vjust = .5), col = c(rep("white", 3), rep("black", 8)))
spl01
ifelse(spl01$group=="F-K", "black", "white")
spl01$label_colors <- ifelse(spl01$group=="F-K", "black", "white")
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = 1) +
geom_text(stat = "count", aes(label = letters),
position = position_stack(vjust = .5), col = c(rep("white", 3), rep("black", 8)))
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = 1) +
geom_text(stat = "count", aes(label = letters),
position = position_stack(vjust = .5), col = spl01$label_colors))
spl01 %>%
ggplot(aes(x = letters, fill = group)) +
geom_bar() +
scale_fill_viridis_d(begin = 0, end = 1) +
geom_text(stat = "count", aes(label = letters),
position = position_stack(vjust = .5), col = spl01$label_colors)
?dpois
plot(x, ppois(x, 1), type = "s", ylab = "F(x)", main = "Poisson(1) CDF")
plot(1:100, ppois(x, 1), type = "s", ylab = "F(x)", main = "Poisson(1) CDF")
plot(x = 1:100, ppois(x, 1), type = "s", ylab = "F(x)", main = "Poisson(1) CDF")
plot(x = 1:100, ppois(x, 1), type = "s", ylab = "F(x)", main = "Poisson(1) CDF")
plot(x = 1:100, ppois(1:100, 1), type = "s", ylab = "F(x)", main = "Poisson(1) CDF")
plot(x = 1:10, ppois(1:10, 1), type = "s", ylab = "F(x)", main = "Poisson(1) CDF")
dpois(10, 2)
rpois(100, 1)
rpois(100, 5)
79800*0.65
39*0.65
40*0.65
7590-6484.33
setwd("~/sciebo/Projekte/snowclones/osf_quaderns")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2: sessionInfo
sessionInfo()
# Chunk 3: pkg
# install CRAN packages (if not yet installed)
sapply(c("readxl", "tidyverse", "patchwork", "devtools", "vroom", "DT"), function(x) if(!is.element(x, installed.packages())) install.packages(x, dependencies = T))
# install non-CRAN packages (if not yet installed)
if(!is.element("concordances", installed.packages())) {
devtools::install_github("hartmast/concordances")
}
# if this doesn't work, check sfla.ch for the package
if(!is.element("collostructions", installed.packages())) {
install.packages("https://sfla.ch/wp-content/uploads/2021/02/collostructions_0.2.0.tar.gz", repos = NULL)
}
# load packages
library(readxl)
library(tidyverse)
library(patchwork)
library(vroom)
library(collostructions)
library(DT)
# Chunk 4
# English
en <- read_xlsx("ENCOW_x_is_the_new_y_without_false_hits.xlsx")
# Spanish
es <- read_xlsx("ESCOW_x_nuev_y_without_false_hits.xlsx")
# German
de <- read_xlsx("DECOW_x_ist_das_neue_y_without_false_hits.xlsx")
# Chunk 5
en <- filter(en, keep=="y")
es <- filter(es, keep=="y")
de <- filter(de, keep=="y")
# add lowercase lemmas
es$lemma_x <- tolower(es$Lemma_x)
es$lemma_y <- tolower(es$Lemma_y)
de$lemma_x <- tolower(de$Lemma_x)
de$lemma_y <- tolower(de$Lemma_y)
# add x-y combinations
paste0(es$lemma_x, es$lemma_y)
# add x-y combinations
paste0(es$lemma_x, es$lemma_y, collapse="_")
# add x-y combinations
paste0(es$lemma_x, es$lemma_y, sep="_")
# add x-y combinations
paste0(es$lemma_x, "-", es$lemma_y)
en$lemma_x <- tolower(en$Lemma_x)
en$lemma_y <- tolower(en$Lemma_y)
es$lemma_x_y <- paste0(es$lemma_x, "-", es$lemma_y)
en$lemma_x_y <- paste0(en$lemma_x, "-", en$lemma_y)
de$lemma_x_y <- paste0(de$lemma_x, "-", de$lemma_y)
# table
tibble(languages = c("English", "German", "Spanish"),
types_x = c(length(unique(en$lemma_x)),
length(unique(de$lemma_x)),
length(unique(es$lemma_x))),
types_y = c(length(unique(en$lemma_y)),
length(unique(de$lemma_y)),
length(unique(es$lemma_y))),
types_x_y = c(length(unique(en$lemma_x_y)),
length(unique(de$lemma_x_y)),
length(unique(es$lemma_x_y)))
)
# get hapaxes
es %>% add_count(wt = lemma_x)
# get hapaxes
es %>% group_by(lemma_x) %>% add_count()
# get hapaxes
es %>% group_by(lemma_x) %>% add_count(name = "freq_x")
# get hapaxes
es %>% group_by(lemma_x) %>% add_count(name = "count_x")
# get hapaxes
es %>% group_by(lemma_x) %>%
add_count(name = "count_x") %>%
ungroup %>% group_by(lema_y) %>%
add_count(name = "count_y")
# get hapaxes
es %>% group_by(lemma_x) %>%
add_count(name = "count_x") %>%
ungroup %>% group_by(lemma_y) %>%
add_count(name = "count_y")
# get hapaxes
es %>% group_by(lemma_x) %>%
add_count(name = "count_x") %>%
ungroup %>% group_by(lemma_y) %>%
add_count(name = "count_y") %>%
ungroup %>% group_by(lemma_x_y) %>%
add_count(name = "count_x_y")
# get hapaxes
es <- es %>% group_by(lemma_x) %>%
add_count(name = "count_x") %>%
ungroup %>% group_by(lemma_y) %>%
add_count(name = "count_y") %>%
ungroup %>% group_by(lemma_x_y) %>%
add_count(name = "count_x_y")
es$count_x
# get hapaxes
en <- en %>% group_by(lemma_x) %>%
add_count(name = "count_x") %>%
ungroup %>% group_by(lemma_y) %>%
add_count(name = "count_y") %>%
ungroup %>% group_by(lemma_x_y) %>%
add_count(name = "count_x_y")
de <- de %>% group_by(lemma_x) %>%
add_count(name = "count_x") %>%
ungroup %>% group_by(lemma_y) %>%
add_count(name = "count_y") %>%
ungroup %>% group_by(lemma_x_y) %>%
add_count(name = "count_x_y")
# table
tibble(languages = c("English", "German", "Spanish"),
tokens = c(nrow(en), nrow(de), nrow(es)),
types_x = c(length(unique(en$lemma_x)),
length(unique(de$lemma_x)),
length(unique(es$lemma_x))),
types_y = c(length(unique(en$lemma_y)),
length(unique(de$lemma_y)),
length(unique(es$lemma_y))),
types_x_y = c(length(unique(en$lemma_x_y)),
length(unique(de$lemma_x_y)),
length(unique(es$lemma_x_y))),
hapaxes_x = c(length(which(en$count_x==1)),
length(which(de$count_x==1)),
length(which(es$count_x==1)))
)
# table
tibble(languages = c("English", "German", "Spanish"),
tokens = c(nrow(en), nrow(de), nrow(es)),
types_x = c(length(unique(en$lemma_x)),
length(unique(de$lemma_x)),
length(unique(es$lemma_x))),
types_y = c(length(unique(en$lemma_y)),
length(unique(de$lemma_y)),
length(unique(es$lemma_y))),
types_x_y = c(length(unique(en$lemma_x_y)),
length(unique(de$lemma_x_y)),
length(unique(es$lemma_x_y))),
hapaxes_x = c(length(which(en$count_x==1)),
length(which(de$count_x==1)),
length(which(es$count_x==1))),
hapaxes_y = c(length(which(en$count_y==1)),
length(which(de$count_y==1)),
length(which(es$count_y==1)))
)
# table
tibble(languages = c("English", "German", "Spanish"),
tokens = c(nrow(en), nrow(de), nrow(es)),
types_x = c(length(unique(en$lemma_x)),
length(unique(de$lemma_x)),
length(unique(es$lemma_x))),
types_y = c(length(unique(en$lemma_y)),
length(unique(de$lemma_y)),
length(unique(es$lemma_y))),
types_x_y = c(length(unique(en$lemma_x_y)),
length(unique(de$lemma_x_y)),
length(unique(es$lemma_x_y))),
hapaxes_x = c(length(which(en$count_x==1)),
length(which(de$count_x==1)),
length(which(es$count_x==1))),
hapaxes_y = c(length(which(en$count_y==1)),
length(which(de$count_y==1)),
length(which(es$count_y==1))),
hapaxes_x_y = c(length(which(en$count_x_y==1)),
length(which(de$count_x_y==1)),
length(which(es$count_x_y==1)))
)
# table
tibble(languages = c("English", "German", "Spanish"),
tokens = c(nrow(en), nrow(de), nrow(es)),
types_x = c(length(unique(en$lemma_x)),
length(unique(de$lemma_x)),
length(unique(es$lemma_x))),
types_y = c(length(unique(en$lemma_y)),
length(unique(de$lemma_y)),
length(unique(es$lemma_y))),
types_x_y = c(length(unique(en$lemma_x_y)),
length(unique(de$lemma_x_y)),
length(unique(es$lemma_x_y))),
hapaxes_x = c(length(which(en$count_x==1)),
length(which(de$count_x==1)),
length(which(es$count_x==1))),
hapaxes_y = c(length(which(en$count_y==1)),
length(which(de$count_y==1)),
length(which(es$count_y==1))),
hapaxes_x_y = c(length(which(en$count_x_y==1)),
length(which(de$count_x_y==1)),
length(which(es$count_x_y==1)))
) %>% writexl::write_xlsx("types_tokens_hapaxes.xlsx")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2: sessionInfo
sessionInfo()
# Chunk 3: pkg
# install CRAN packages (if not yet installed)
sapply(c("readxl", "tidyverse", "patchwork", "devtools", "vroom", "DT"), function(x) if(!is.element(x, installed.packages())) install.packages(x, dependencies = T))
# install non-CRAN packages (if not yet installed)
if(!is.element("concordances", installed.packages())) {
devtools::install_github("hartmast/concordances")
}
# if this doesn't work, check sfla.ch for the package
if(!is.element("collostructions", installed.packages())) {
install.packages("https://sfla.ch/wp-content/uploads/2021/02/collostructions_0.2.0.tar.gz", repos = NULL)
}
# load packages
library(readxl)
library(tidyverse)
library(patchwork)
library(vroom)
library(collostructions)
library(DT)
# Chunk 4
# English
en <- read_xlsx("ENCOW_x_is_the_new_y_without_false_hits.xlsx")
# Spanish
es <- read_xlsx("ESCOW_x_nuev_y_without_false_hits.xlsx")
# German
de <- read_xlsx("DECOW_x_ist_das_neue_y_without_false_hits.xlsx")
# Chunk 5
en <- filter(en, keep=="y")
es <- filter(es, keep=="y")
de <- filter(de, keep=="y")
# Chunk 6
# add lowercase lemmas
es$lemma_x <- tolower(es$Lemma_x)
es$lemma_y <- tolower(es$Lemma_y)
de$lemma_x <- tolower(de$Lemma_x)
de$lemma_y <- tolower(de$Lemma_y)
en$lemma_x <- tolower(en$Lemma_x)
en$lemma_y <- tolower(en$Lemma_y)
# add x-y combinations
es$lemma_x_y <- paste0(es$lemma_x, "-", es$lemma_y)
en$lemma_x_y <- paste0(en$lemma_x, "-", en$lemma_y)
de$lemma_x_y <- paste0(de$lemma_x, "-", de$lemma_y)
# get hapaxes --> add frequency counts
en <- en %>% group_by(lemma_x) %>%
add_count(name = "count_x") %>%
ungroup %>% group_by(lemma_y) %>%
add_count(name = "count_y") %>%
ungroup %>% group_by(lemma_x_y) %>%
add_count(name = "count_x_y")
es <- es %>% group_by(lemma_x) %>%
add_count(name = "count_x") %>%
ungroup %>% group_by(lemma_y) %>%
add_count(name = "count_y") %>%
ungroup %>% group_by(lemma_x_y) %>%
add_count(name = "count_x_y")
de <- de %>% group_by(lemma_x) %>%
add_count(name = "count_x") %>%
ungroup %>% group_by(lemma_y) %>%
add_count(name = "count_y") %>%
ungroup %>% group_by(lemma_x_y) %>%
add_count(name = "count_x_y")
# table
tibble(languages = c("English", "German", "Spanish"),
tokens = c(nrow(en), nrow(de), nrow(es)),
types_x = c(length(unique(en$lemma_x)),
length(unique(de$lemma_x)),
length(unique(es$lemma_x))),
types_y = c(length(unique(en$lemma_y)),
length(unique(de$lemma_y)),
length(unique(es$lemma_y))),
types_x_y = c(length(unique(en$lemma_x_y)),
length(unique(de$lemma_x_y)),
length(unique(es$lemma_x_y))),
hapaxes_x = c(length(which(en$count_x==1)),
length(which(de$count_x==1)),
length(which(es$count_x==1))),
hapaxes_y = c(length(which(en$count_y==1)),
length(which(de$count_y==1)),
length(which(es$count_y==1))),
hapaxes_x_y = c(length(which(en$count_x_y==1)),
length(which(de$count_x_y==1)),
length(which(es$count_x_y==1)))
)
# ESCOW lemma frequencies
escow <- read_csv("es_cow_lemmas.csv")
# DECOW lemma frequencies
decow <- read_csv("de_cow_lemmas.csv")
# ESCOW pos frequencies
es_pos <- read_csv("frequency_lists/ESCOW_pos_frequencies.csv")
# DECOW pos frequencies
de_pos <- read_csv("frequency_lists/decow_pos_frequencies.csv")
# get total number of nouns and adjectives
n_a_freq <- filter(es_pos, pos %in% c("NOUN", "ADP", "PROPN", "ADJ")) %>% select(frequency) %>% sum
n_a_freq_de <- filter(de_pos, tag %in% c("NN", "ADJA", "ADJD", "NE", "NN"))
# for the collostructional analysis,
# reduce two-word lemmas to the last word
# (compound heads for compounds, last names
# for person names)
de$lemma_x <- gsub(".* ", "", de$lemma_x)
de$lemma_y <- gsub(".* ", "", de$lemma_y)
# create input for coll. anal. for
# x slot
input_x <- table(es$lemma_x) %>% as_tibble(.name_repair="unique") %>% setNames(c("Lemma", "Freq_in_cxn"))
input_x_de <- table(de$lemma_x) %>% as_tibble(.name_repair="unique") %>% setNames(c("Lemma", "Freq_in_cxn"))
# lowercase lemma in escow
escow$lemma <- tolower(escow$token...)
# lowercase lemma in decow
decow$lemma <- tolower(decow$Lemma)
decow <- decow %>% group_by(lemma) %>% summarise(
Freq = sum(Freq)
)
# join dataframes to combine lemma and corpus freqs
input_x <- left_join(input_x, select(escow, lemma, f_raw),
by = c("Lemma" = "lemma"))
input_x_de <- left_join(input_x_de, select(decow, lemma, Freq),
by = c("Lemma" = "lemma"))
# replace NA by 0
input_x <- input_x %>% replace_na(list(Freq_in_cxn = 0, f_raw = 0))
input_x_de <- input_x_de %>% replace_na(list(Freq_in_cxn = 0, Freq = 0))
# omit all with f_raw < Freq_in_cxn
input_x <- input_x[which(input_x$f_raw>=input_x$Freq_in_cxn),]
input_x_de <- input_x_de[which(input_x_de$Freq >= input_x_de$Freq_in_cxn),]
# generate input for coll. anal.
input_y_de <- table(de$lemma_y) %>% as_tibble(.name_repair="unique") %>% setNames(c("Lemma", "Freq_in_cxn"))
# join dataframes to combine lemma and corpus freqs
input_y <- left_join(input_y_de, select(escow, lemma, f_raw),
by = c("Lemma" = "lemma"))
input_y_de <- left_join(input_y_de, select(decow, lemma, Freq),
by = c("Lemma" = "lemma"))
# replace NA by 0
input_y_de <- input_y_de %>% replace_na(list(Freq_in_cxn = 0, Freq = 0))
input_y_de <- input_y_de[which(input_y_de$Freq >= input_y_de$Freq_in_cxn),]
# coll. anal.
collex_x <- collex(as.data.frame(input_x), corpsize = n_a_freq)
# create input for coll. anal. for
# x slot
input_y <- table(es$lemma_y) %>% as_tibble(.name_repair="unique") %>% setNames(c("Lemma", "Freq_in_cxn"))
input_y <- left_join(input_y, select(escow, lemma, f_raw),
by = c("Lemma" = "lemma"))
# replace NA by 0
input_y <- input_y %>% replace_na(list(Freq_in_cxn = 0, f_raw = 0))
# omit all with f_raw < Freq_in_cxn
input_y <- input_y[which(input_y$f_raw>=input_y$Freq_in_cxn),]
input_x
input_y
# coll. anal.
collex_y <- collex(as.data.frame(input_y), corpsize = n_a_freq)
collex_x
collex_y
collex_x_de <- input_x_de %>% as.data.frame %>% collex(corpsize = sum(n_a_freq_de$frequency))
collex_y_de <- input_y_de %>% as.data.frame %>% collex(corpsize = sum(n_a_freq_de$frequency))
es %>% select(lemma_x, lemma_y) %>% as.data.frame() %>% collex.covar() %>% DT::datatable()
es %>% select(lemma_x, lemma_y)
es %>% select("lemma_x", "lemma_y") %>% as.data.frame() %>% collex.covar() %>% DT::datatable()
es %>% select(lemma_x, lemma_y) %>% as.data.frame() %>% collex.covar() %>% DT::datatable()
es %>% select(lemma_x, lemma_y)
es %>% select(lemma_x, lemma_y, -lemma_x_y) %>% as.data.frame() %>% collex.covar() %>% DT::datatable()
es %>% select(lemma_x, lemma_y) %>% as.data.frame() %>% collex.covar() %>% DT::datatable()
?select
es %>% select(matches(lemma_x), matches(lemma_y))
es %>% select(matches("lemma_x"), matches("lemma_y"))
es %>% select(ends_with("lemma_x"), ends_with("lemma_y"))
es %>% ungroup %>% select(ends_with("lemma_x"), ends_with("lemma_y"))
es %>% ungroup %>% select(lemma_x, lemma_y)
es %>% ungroup %>% select(lemma_x, lemma_y) %>% as.data.frame() %>% collex.covar() %>% DT::datatable()
de %>% ungroup %>% select(lemma_x, lemma_y) %>% as.data.frame() %>% collex.covar() %>% DT::datatable()
